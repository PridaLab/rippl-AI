{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rippl_AI\n",
    "import aux_fcn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data download\n",
    "4 uLED sessions will be downloaded: Amigo2 and Som2 will be used for training ; Dlx1 and Thy7 for validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from figshare.figshare.figshare import Figshare\n",
    "fshare = Figshare()\n",
    "\n",
    "article_ids = [16847521,16856137,14959449,14960085] \n",
    "sess=['Amigo2','Som2','Dlx1','Thy7']                                  \n",
    "for id,s in zip(article_ids,sess):\n",
    "    datapath = os.path.join('Downloaded_data', f'{s}')\n",
    "    if os.path.isdir(datapath):\n",
    "        print(f\"{s} session already exists. Moving on.\")\n",
    "    else:\n",
    "        print(\"Downloading data... Please wait, this might take up some time\")        # Can take up to 10 minutes\n",
    "        fshare.retrieve_files_from_article(id,directory=datapath)\n",
    "        print(\"Data downloaded!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data load\n",
    "The training sessions' LFP will be appended together in a list. The same will happen with the ripples detection times.\n",
    "That is the required input for the training parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The training sessions will be appended together. Do the same with your training data\n",
    "train_LFPs=[]\n",
    "train_GTs=[]\n",
    "# Amigo2\n",
    "path=os.path.join('Downloaded_data','Amigo2','figshare_16847521')\n",
    "LFP,GT=aux_fcn.load_lab_data(path)\n",
    "train_LFPs.append(LFP)\n",
    "train_GTs.append(GT)\n",
    "\n",
    "# Som2\n",
    "path=os.path.join('Downloaded_data','Som2','figshare_16856137')\n",
    "LFP,GT=aux_fcn.load_lab_data(path)\n",
    "train_LFPs.append(LFP)\n",
    "train_GTs.append(GT)\n",
    "## Append all your validation sessions\n",
    "val_LFPs=[]\n",
    "val_GTs=[]\n",
    "# Dlx1 Validation\n",
    "path=os.path.join('Downloaded_data','Dlx1','figshare_14959449')\n",
    "LFP,GT=aux_fcn.load_lab_data(path)\n",
    "val_LFPs.append(LFP)\n",
    "val_GTs.append(GT)\n",
    "# Thy07 Validation\n",
    "path=os.path.join('Downloaded_data','Thy7','figshare_14960085')\n",
    "LFP,GT=aux_fcn.load_lab_data(path)\n",
    "val_LFPs.append(LFP)\n",
    "val_GTs.append(GT)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training sessions are concatenated, the validation sessions are kept as different sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrain_LFP_norm,retrain_GT,val_LFP_norm,val_GT=rippl_AI.prepare_training_data(train_LFPs,train_GTs,val_LFPs,val_GTs,sf=30000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retraining examples for the different models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBOOST\n",
    "XGBOOST does not require further parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rippl_AI.retrain_model(retrain_LFP_norm,retrain_GT,val_LFP_norm,val_GT,arch='XGBOOST',\n",
    "                       save_path=os.path.join('retrained_models','XGBOOST_retrained1'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM\n",
    "Has only one parameter: \n",
    "'Undersampler proportion': It controls the number of windows with negatives (no ripples) that will be used to train the model. Following the formula: Undersampler proportion= (Positive windows)/(Negative windows). 1 means the same number of poitive and negative windows. Low values can lead to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'Unsersampler proportion': 0.1}\n",
    "\n",
    "rippl_AI.retrain_model(retrain_LFP_norm,retrain_GT,val_LFP_norm,val_GT,arch='SVM',parameters=params,\n",
    "                       save_path=os.path.join('retrained_models','SVM_retrained1'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM \n",
    "LSTM has two training parameters:\n",
    "'Epochs': is the number of times that the training data is fed to the model\n",
    "'Training batch': is the number of windows that are processed before updating the weights during training. Higher values prevent big weight oscillations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'Epochs': 2,\n",
    "        'Training batch': 32}\n",
    "rippl_AI.retrain_model(retrain_LFP_norm,retrain_GT,val_LFP_norm,val_GT,arch='LSTM',parameters=params,\n",
    "                       save_path=os.path.join('retrained_models','LSTM_retrained1'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN2D\n",
    "CNN2D share training parameters with th LSTM architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'Epochs': 1,\n",
    "        'Training batch': 64}\n",
    "rippl_AI.retrain_model(retrain_LFP_norm,retrain_GT,val_LFP_norm,val_GT,arch='CNN2D',parameters=params,\n",
    "                       save_path=os.path.join('retrained_models','CNN2D_retrained1'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN1D\n",
    "CNN1D share training parameters with LSTM and CNN2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'Epochs': 2,\n",
    "        'Training batch': 32}\n",
    "rippl_AI.retrain_model(retrain_LFP_norm,retrain_GT,val_LFP_norm,val_GT,arch='CNN1D',parameters=params,save_path=os.path.join('retrained_models','CNN1D_retrained1'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PublicBCG_d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
